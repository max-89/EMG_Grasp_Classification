{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    " \n",
    "from numpy.random import seed\n",
    "seed(888)\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "\n",
    "tf.random.set_seed(404)\n",
    "\n",
    "from IPython.display import display\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from time import strftime\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('downsampled.csv')\n",
    "\n",
    "df.drop('Unnamed: 0',inplace=True,axis=1)\n",
    "\n",
    "df_copy=df.copy()\n",
    "Y=np.array(df_copy['stimulus'])\n",
    "\n",
    "df_copy.drop(labels='stimulus',axis=1,inplace=True)\n",
    "X=np.array(df_copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sc = StandardScaler()\n",
    "#X = sc.fit_transform(X)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "X=scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=abs(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size=0.2, shuffle= True)\n",
    "\n",
    "\n",
    "X_train=abs(X_train)\n",
    "X_test=abs(X_test)\n",
    "X_train.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network():\n",
    "\n",
    "    # Initialising the ANN\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units = 256, kernel_initializer = 'uniform', activation = 'relu', input_dim = 68))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 256, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 256, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27389 samples\n",
      "Epoch 1/52\n",
      "27389/27389 [==============================] - 5s 187us/sample - loss: 1.1248 - accuracy: 0.5230\n",
      "Epoch 2/52\n",
      "27389/27389 [==============================] - 4s 157us/sample - loss: 0.8581 - accuracy: 0.6464\n",
      "Epoch 3/52\n",
      "27389/27389 [==============================] - 3s 92us/sample - loss: 0.7380 - accuracy: 0.7040\n",
      "Epoch 4/52\n",
      "27389/27389 [==============================] - 2s 62us/sample - loss: 0.6728 - accuracy: 0.7311\n",
      "Epoch 5/52\n",
      "27389/27389 [==============================] - 2s 64us/sample - loss: 0.6109 - accuracy: 0.7599\n",
      "Epoch 6/52\n",
      "27389/27389 [==============================] - 2s 71us/sample - loss: 0.5823 - accuracy: 0.7700\n",
      "Epoch 7/52\n",
      "27389/27389 [==============================] - 2s 78us/sample - loss: 0.5460 - accuracy: 0.7838\n",
      "Epoch 8/52\n",
      "27389/27389 [==============================] - 2s 81us/sample - loss: 0.5255 - accuracy: 0.7933\n",
      "Epoch 9/52\n",
      "27389/27389 [==============================] - 2s 81us/sample - loss: 0.4982 - accuracy: 0.8043\n",
      "Epoch 10/52\n",
      "27389/27389 [==============================] - 2s 80us/sample - loss: 0.4751 - accuracy: 0.8131\n",
      "Epoch 11/52\n",
      "27389/27389 [==============================] - 2s 81us/sample - loss: 0.4637 - accuracy: 0.8178\n",
      "Epoch 12/52\n",
      "27389/27389 [==============================] - 2s 80us/sample - loss: 0.4395 - accuracy: 0.8262\n",
      "Epoch 13/52\n",
      "27389/27389 [==============================] - 3s 105us/sample - loss: 0.4239 - accuracy: 0.8358\n",
      "Epoch 14/52\n",
      "27389/27389 [==============================] - 3s 108us/sample - loss: 0.4163 - accuracy: 0.8393\n",
      "Epoch 15/52\n",
      "27389/27389 [==============================] - 4s 142us/sample - loss: 0.4106 - accuracy: 0.8410\n",
      "Epoch 16/52\n",
      "27389/27389 [==============================] - 4s 155us/sample - loss: 0.3808 - accuracy: 0.8528\n",
      "Epoch 17/52\n",
      "27389/27389 [==============================] - 3s 103us/sample - loss: 0.3760 - accuracy: 0.8568\n",
      "Epoch 18/52\n",
      "27389/27389 [==============================] - 2s 81us/sample - loss: 0.3622 - accuracy: 0.8609\n",
      "Epoch 19/52\n",
      "27389/27389 [==============================] - 2s 82us/sample - loss: 0.3470 - accuracy: 0.8655\n",
      "Epoch 20/52\n",
      "27389/27389 [==============================] - 4s 135us/sample - loss: 0.3419 - accuracy: 0.8689\n",
      "Epoch 21/52\n",
      "27389/27389 [==============================] - 4s 161us/sample - loss: 0.3304 - accuracy: 0.8732\n",
      "Epoch 22/52\n",
      "27389/27389 [==============================] - 4s 149us/sample - loss: 0.3149 - accuracy: 0.8794\n",
      "Epoch 23/52\n",
      "27389/27389 [==============================] - 5s 168us/sample - loss: 0.3202 - accuracy: 0.8791\n",
      "Epoch 24/52\n",
      "27389/27389 [==============================] - 4s 161us/sample - loss: 0.3032 - accuracy: 0.8843\n",
      "Epoch 25/52\n",
      "27389/27389 [==============================] - 4s 147us/sample - loss: 0.2888 - accuracy: 0.8896\n",
      "Epoch 26/52\n",
      "27389/27389 [==============================] - 4s 155us/sample - loss: 0.2929 - accuracy: 0.8874\n",
      "Epoch 27/52\n",
      "27389/27389 [==============================] - 4s 155us/sample - loss: 0.2820 - accuracy: 0.8926\n",
      "Epoch 28/52\n",
      "27389/27389 [==============================] - 4s 155us/sample - loss: 0.2666 - accuracy: 0.9000\n",
      "Epoch 29/52\n",
      "27389/27389 [==============================] - 4s 155us/sample - loss: 0.2586 - accuracy: 0.9000\n",
      "Epoch 30/52\n",
      "27389/27389 [==============================] - 4s 155us/sample - loss: 0.2538 - accuracy: 0.9031\n",
      "Epoch 31/52\n",
      "27389/27389 [==============================] - 4s 155us/sample - loss: 0.2483 - accuracy: 0.9058\n",
      "Epoch 32/52\n",
      "27389/27389 [==============================] - 4s 154us/sample - loss: 0.2490 - accuracy: 0.9070\n",
      "Epoch 33/52\n",
      "27389/27389 [==============================] - 3s 128us/sample - loss: 0.2341 - accuracy: 0.9114\n",
      "Epoch 34/52\n",
      "27389/27389 [==============================] - 4s 156us/sample - loss: 0.2344 - accuracy: 0.9117\n",
      "Epoch 35/52\n",
      "27389/27389 [==============================] - 4s 155us/sample - loss: 0.2217 - accuracy: 0.9167\n",
      "Epoch 36/52\n",
      "27389/27389 [==============================] - 4s 155us/sample - loss: 0.2244 - accuracy: 0.9156\n",
      "Epoch 37/52\n",
      "27389/27389 [==============================] - 3s 128us/sample - loss: 0.2137 - accuracy: 0.9181\n",
      "Epoch 38/52\n",
      "27389/27389 [==============================] - 4s 146us/sample - loss: 0.2138 - accuracy: 0.9189\n",
      "Epoch 39/52\n",
      "27389/27389 [==============================] - 4s 155us/sample - loss: 0.2058 - accuracy: 0.9221\n",
      "Epoch 40/52\n",
      "27389/27389 [==============================] - 4s 155us/sample - loss: 0.1973 - accuracy: 0.9276\n",
      "Epoch 41/52\n",
      "27389/27389 [==============================] - 4s 152us/sample - loss: 0.1979 - accuracy: 0.9258\n",
      "Epoch 42/52\n",
      "27389/27389 [==============================] - 4s 155us/sample - loss: 0.1943 - accuracy: 0.9276\n",
      "Epoch 43/52\n",
      "27389/27389 [==============================] - 4s 156us/sample - loss: 0.1913 - accuracy: 0.9277\n",
      "Epoch 44/52\n",
      "27389/27389 [==============================] - 4s 154us/sample - loss: 0.1850 - accuracy: 0.9305\n",
      "Epoch 45/52\n",
      "27389/27389 [==============================] - 4s 154us/sample - loss: 0.1780 - accuracy: 0.9341\n",
      "Epoch 46/52\n",
      "27389/27389 [==============================] - 4s 148us/sample - loss: 0.1836 - accuracy: 0.9332\n",
      "Epoch 47/52\n",
      "27389/27389 [==============================] - 3s 112us/sample - loss: 0.1722 - accuracy: 0.9367\n",
      "Epoch 48/52\n",
      "27389/27389 [==============================] - 4s 155us/sample - loss: 0.1834 - accuracy: 0.9312\n",
      "Epoch 49/52\n",
      "27389/27389 [==============================] - 4s 141us/sample - loss: 0.1685 - accuracy: 0.9369\n",
      "Epoch 50/52\n",
      "27389/27389 [==============================] - 4s 155us/sample - loss: 0.1588 - accuracy: 0.9417\n",
      "Epoch 51/52\n",
      "27389/27389 [==============================] - 4s 156us/sample - loss: 0.1679 - accuracy: 0.9377\n",
      "Epoch 52/52\n",
      "27389/27389 [==============================] - 4s 140us/sample - loss: 0.1570 - accuracy: 0.9418\n",
      "6848/6848 - 1s - loss: 0.1533 - accuracy: 0.9449\n"
     ]
    }
   ],
   "source": [
    "classifier= create_network()\n",
    "history= classifier.fit(X_train,y_train,epochs=52,batch_size=70)\n",
    "score,acc= classifier.evaluate(X_test,y_test, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24650 samples\n",
      "Epoch 1/52\n",
      "24650/24650 [==============================] - 2s 64us/sample - loss: 1.0246 - accuracy: 0.5813\n",
      "Epoch 2/52\n",
      "24650/24650 [==============================] - 1s 37us/sample - loss: 0.7292 - accuracy: 0.7085\n",
      "Epoch 3/52\n",
      "24650/24650 [==============================] - 1s 37us/sample - loss: 0.6411 - accuracy: 0.7453\n",
      "Epoch 4/52\n",
      "24650/24650 [==============================] - 1s 38us/sample - loss: 0.5908 - accuracy: 0.7660\n",
      "Epoch 5/52\n",
      "24650/24650 [==============================] - 1s 38us/sample - loss: 0.5554 - accuracy: 0.7789\n",
      "Epoch 6/52\n",
      "24650/24650 [==============================] - 4s 169us/sample - loss: 0.5145 - accuracy: 0.7946\n",
      "Epoch 7/52\n",
      "24650/24650 [==============================] - 2s 80us/sample - loss: 0.4970 - accuracy: 0.8017\n",
      "Epoch 8/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.4648 - accuracy: 0.8153\n",
      "Epoch 9/52\n",
      "24650/24650 [==============================] - 2s 78us/sample - loss: 0.4528 - accuracy: 0.8202\n",
      "Epoch 10/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.4310 - accuracy: 0.8334\n",
      "Epoch 11/52\n",
      "24650/24650 [==============================] - 2s 78us/sample - loss: 0.4112 - accuracy: 0.8391\n",
      "Epoch 12/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.3933 - accuracy: 0.8450\n",
      "Epoch 13/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.3718 - accuracy: 0.8508\n",
      "Epoch 14/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.3765 - accuracy: 0.8538\n",
      "Epoch 15/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.3478 - accuracy: 0.8628\n",
      "Epoch 16/52\n",
      "24650/24650 [==============================] - 2s 95us/sample - loss: 0.3345 - accuracy: 0.8710\n",
      "Epoch 17/52\n",
      "24650/24650 [==============================] - 2s 98us/sample - loss: 0.3201 - accuracy: 0.8753\n",
      "Epoch 18/52\n",
      "24650/24650 [==============================] - 2s 83us/sample - loss: 0.3101 - accuracy: 0.8774\n",
      "Epoch 19/52\n",
      "24650/24650 [==============================] - 3s 102us/sample - loss: 0.3006 - accuracy: 0.8844\n",
      "Epoch 20/52\n",
      "24650/24650 [==============================] - 3s 104us/sample - loss: 0.2912 - accuracy: 0.8867\n",
      "Epoch 21/52\n",
      "24650/24650 [==============================] - 2s 80us/sample - loss: 0.2695 - accuracy: 0.8963\n",
      "Epoch 22/52\n",
      "24650/24650 [==============================] - 2s 85us/sample - loss: 0.2580 - accuracy: 0.9010\n",
      "Epoch 23/52\n",
      "24650/24650 [==============================] - 3s 111us/sample - loss: 0.2590 - accuracy: 0.9017\n",
      "Epoch 24/52\n",
      "24650/24650 [==============================] - 3s 110us/sample - loss: 0.2580 - accuracy: 0.9021\n",
      "Epoch 25/52\n",
      "24650/24650 [==============================] - 3s 111us/sample - loss: 0.2443 - accuracy: 0.9032\n",
      "Epoch 26/52\n",
      "24650/24650 [==============================] - 3s 111us/sample - loss: 0.2318 - accuracy: 0.9111\n",
      "Epoch 27/52\n",
      "24650/24650 [==============================] - 3s 110us/sample - loss: 0.2201 - accuracy: 0.9174\n",
      "Epoch 28/52\n",
      "24650/24650 [==============================] - 3s 111us/sample - loss: 0.2147 - accuracy: 0.9185\n",
      "Epoch 29/52\n",
      "24650/24650 [==============================] - 3s 110us/sample - loss: 0.1986 - accuracy: 0.9244\n",
      "Epoch 30/52\n",
      "24650/24650 [==============================] - 3s 111us/sample - loss: 0.1972 - accuracy: 0.9238\n",
      "Epoch 31/52\n",
      "24650/24650 [==============================] - 2s 84us/sample - loss: 0.1859 - accuracy: 0.9309\n",
      "Epoch 32/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.1749 - accuracy: 0.9362\n",
      "Epoch 33/52\n",
      "24650/24650 [==============================] - 3s 112us/sample - loss: 0.1766 - accuracy: 0.9335\n",
      "Epoch 34/52\n",
      "24650/24650 [==============================] - 3s 110us/sample - loss: 0.1637 - accuracy: 0.9383\n",
      "Epoch 35/52\n",
      "24650/24650 [==============================] - 3s 110us/sample - loss: 0.1704 - accuracy: 0.9353\n",
      "Epoch 36/52\n",
      "24650/24650 [==============================] - 3s 105us/sample - loss: 0.1620 - accuracy: 0.9404\n",
      "Epoch 37/52\n",
      "24650/24650 [==============================] - 2s 78us/sample - loss: 0.1443 - accuracy: 0.9482\n",
      "Epoch 38/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1553 - accuracy: 0.9442\n",
      "Epoch 39/52\n",
      "24650/24650 [==============================] - 2s 78us/sample - loss: 0.1455 - accuracy: 0.9448\n",
      "Epoch 40/52\n",
      "24650/24650 [==============================] - 3s 110us/sample - loss: 0.1474 - accuracy: 0.9464\n",
      "Epoch 41/52\n",
      "24650/24650 [==============================] - 2s 93us/sample - loss: 0.1259 - accuracy: 0.9538\n",
      "Epoch 42/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.1301 - accuracy: 0.9512\n",
      "Epoch 43/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.1310 - accuracy: 0.9530\n",
      "Epoch 44/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1272 - accuracy: 0.9526\n",
      "Epoch 45/52\n",
      "24650/24650 [==============================] - 2s 80us/sample - loss: 0.1316 - accuracy: 0.9523\n",
      "Epoch 46/52\n",
      "24650/24650 [==============================] - 2s 82us/sample - loss: 0.1299 - accuracy: 0.9546\n",
      "Epoch 47/52\n",
      "24650/24650 [==============================] - 2s 78us/sample - loss: 0.1092 - accuracy: 0.9602\n",
      "Epoch 48/52\n",
      "24650/24650 [==============================] - 2s 79us/sample - loss: 0.1241 - accuracy: 0.9539\n",
      "Epoch 49/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.1222 - accuracy: 0.9549\n",
      "Epoch 50/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1058 - accuracy: 0.9609\n",
      "Epoch 51/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1061 - accuracy: 0.9624\n",
      "Epoch 52/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.0974 - accuracy: 0.9650\n",
      "2739/2739 [==============================] - 0s 128us/sample - loss: 0.1090 - accuracy: 0.9609\n",
      "Train on 24650 samples\n",
      "Epoch 1/52\n",
      "24650/24650 [==============================] - 4s 144us/sample - loss: 1.0219 - accuracy: 0.5786\n",
      "Epoch 2/52\n",
      "24650/24650 [==============================] - 3s 106us/sample - loss: 0.7430 - accuracy: 0.7005\n",
      "Epoch 3/52\n",
      "24650/24650 [==============================] - 3s 105us/sample - loss: 0.6464 - accuracy: 0.7429\n",
      "Epoch 4/52\n",
      "24650/24650 [==============================] - 3s 104us/sample - loss: 0.6036 - accuracy: 0.7615\n",
      "Epoch 5/52\n",
      "24650/24650 [==============================] - 3s 105us/sample - loss: 0.5527 - accuracy: 0.7806\n",
      "Epoch 6/52\n",
      "24650/24650 [==============================] - 3s 104us/sample - loss: 0.5230 - accuracy: 0.7927\n",
      "Epoch 7/52\n",
      "24650/24650 [==============================] - 3s 105us/sample - loss: 0.5011 - accuracy: 0.8036\n",
      "Epoch 8/52\n",
      "24650/24650 [==============================] - 3s 105us/sample - loss: 0.4818 - accuracy: 0.8095\n",
      "Epoch 9/52\n",
      "24650/24650 [==============================] - 2s 98us/sample - loss: 0.4641 - accuracy: 0.8155\n",
      "Epoch 10/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.4489 - accuracy: 0.8213\n",
      "Epoch 11/52\n",
      "24650/24650 [==============================] - 2s 91us/sample - loss: 0.4207 - accuracy: 0.8356\n",
      "Epoch 12/52\n",
      "24650/24650 [==============================] - 2s 101us/sample - loss: 0.4003 - accuracy: 0.8441\n",
      "Epoch 13/52\n",
      "24650/24650 [==============================] - 2s 81us/sample - loss: 0.3837 - accuracy: 0.8486\n",
      "Epoch 14/52\n",
      "24650/24650 [==============================] - 2s 80us/sample - loss: 0.3651 - accuracy: 0.8589\n",
      "Epoch 15/52\n",
      "24650/24650 [==============================] - 2s 80us/sample - loss: 0.3621 - accuracy: 0.8612\n",
      "Epoch 16/52\n",
      "24650/24650 [==============================] - 2s 80us/sample - loss: 0.3425 - accuracy: 0.8661\n",
      "Epoch 17/52\n",
      "24650/24650 [==============================] - 2s 80us/sample - loss: 0.3389 - accuracy: 0.8687\n",
      "Epoch 18/52\n",
      "24650/24650 [==============================] - 2s 80us/sample - loss: 0.3201 - accuracy: 0.8755\n",
      "Epoch 19/52\n",
      "24650/24650 [==============================] - 2s 80us/sample - loss: 0.2954 - accuracy: 0.8869\n",
      "Epoch 20/52\n",
      "24650/24650 [==============================] - 2s 80us/sample - loss: 0.2964 - accuracy: 0.8856\n",
      "Epoch 21/52\n",
      "24650/24650 [==============================] - 2s 78us/sample - loss: 0.2755 - accuracy: 0.8929\n",
      "Epoch 22/52\n",
      "24650/24650 [==============================] - 2s 81us/sample - loss: 0.2696 - accuracy: 0.8977\n",
      "Epoch 23/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24650/24650 [==============================] - 2s 81us/sample - loss: 0.2678 - accuracy: 0.8985\n",
      "Epoch 24/52\n",
      "24650/24650 [==============================] - 2s 81us/sample - loss: 0.2509 - accuracy: 0.9047\n",
      "Epoch 25/52\n",
      "24650/24650 [==============================] - 3s 109us/sample - loss: 0.2492 - accuracy: 0.9055\n",
      "Epoch 26/52\n",
      "24650/24650 [==============================] - 3s 119us/sample - loss: 0.2312 - accuracy: 0.9099\n",
      "Epoch 27/52\n",
      "24650/24650 [==============================] - 3s 118us/sample - loss: 0.2248 - accuracy: 0.9117\n",
      "Epoch 28/52\n",
      "24650/24650 [==============================] - 3s 104us/sample - loss: 0.2161 - accuracy: 0.9176\n",
      "Epoch 29/52\n",
      "24650/24650 [==============================] - 2s 81us/sample - loss: 0.2157 - accuracy: 0.9191\n",
      "Epoch 30/52\n",
      "24650/24650 [==============================] - 2s 78us/sample - loss: 0.2027 - accuracy: 0.9239\n",
      "Epoch 31/52\n",
      "24650/24650 [==============================] - 2s 82us/sample - loss: 0.1886 - accuracy: 0.9292\n",
      "Epoch 32/52\n",
      "24650/24650 [==============================] - 2s 82us/sample - loss: 0.1974 - accuracy: 0.9255\n",
      "Epoch 33/52\n",
      "24650/24650 [==============================] - 2s 81us/sample - loss: 0.1815 - accuracy: 0.9336\n",
      "Epoch 34/52\n",
      "24650/24650 [==============================] - 2s 81us/sample - loss: 0.1782 - accuracy: 0.9343\n",
      "Epoch 35/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1751 - accuracy: 0.9356\n",
      "Epoch 36/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1634 - accuracy: 0.9407\n",
      "Epoch 37/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.1663 - accuracy: 0.9373\n",
      "Epoch 38/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1577 - accuracy: 0.9431\n",
      "Epoch 39/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.1553 - accuracy: 0.9426\n",
      "Epoch 40/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1454 - accuracy: 0.9452\n",
      "Epoch 41/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.1477 - accuracy: 0.9455\n",
      "Epoch 42/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.1378 - accuracy: 0.9491\n",
      "Epoch 43/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1388 - accuracy: 0.9490\n",
      "Epoch 44/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1345 - accuracy: 0.9490\n",
      "Epoch 45/52\n",
      "24650/24650 [==============================] - 3s 129us/sample - loss: 0.1241 - accuracy: 0.9553\n",
      "Epoch 46/52\n",
      "24650/24650 [==============================] - 3s 128us/sample - loss: 0.1290 - accuracy: 0.9516\n",
      "Epoch 47/52\n",
      "24650/24650 [==============================] - 3s 129us/sample - loss: 0.1207 - accuracy: 0.9571\n",
      "Epoch 48/52\n",
      "24650/24650 [==============================] - 3s 130us/sample - loss: 0.1183 - accuracy: 0.9574\n",
      "Epoch 49/52\n",
      "24650/24650 [==============================] - 3s 129us/sample - loss: 0.1094 - accuracy: 0.9603\n",
      "Epoch 50/52\n",
      "24650/24650 [==============================] - 3s 129us/sample - loss: 0.1225 - accuracy: 0.9561\n",
      "Epoch 51/52\n",
      "24650/24650 [==============================] - 3s 129us/sample - loss: 0.1110 - accuracy: 0.9597\n",
      "Epoch 52/52\n",
      "24650/24650 [==============================] - 3s 129us/sample - loss: 0.1080 - accuracy: 0.9611\n",
      "2739/2739 [==============================] - 0s 130us/sample - loss: 0.1134 - accuracy: 0.9555\n",
      "Train on 24650 samples\n",
      "Epoch 1/52\n",
      "24650/24650 [==============================] - 4s 149us/sample - loss: 1.0133 - accuracy: 0.5872\n",
      "Epoch 2/52\n",
      "24650/24650 [==============================] - 3s 127us/sample - loss: 0.7401 - accuracy: 0.7036\n",
      "Epoch 3/52\n",
      "24650/24650 [==============================] - 3s 127us/sample - loss: 0.6419 - accuracy: 0.7456\n",
      "Epoch 4/52\n",
      "24650/24650 [==============================] - 3s 129us/sample - loss: 0.5880 - accuracy: 0.7692\n",
      "Epoch 5/52\n",
      "24650/24650 [==============================] - 3s 127us/sample - loss: 0.5543 - accuracy: 0.7789\n",
      "Epoch 6/52\n",
      "24650/24650 [==============================] - 2s 90us/sample - loss: 0.5145 - accuracy: 0.7968\n",
      "Epoch 7/52\n",
      "24650/24650 [==============================] - 3s 108us/sample - loss: 0.4973 - accuracy: 0.8013\n",
      "Epoch 8/52\n",
      "24650/24650 [==============================] - 2s 101us/sample - loss: 0.4647 - accuracy: 0.8140\n",
      "Epoch 9/52\n",
      "24650/24650 [==============================] - 2s 86us/sample - loss: 0.4485 - accuracy: 0.8233\n",
      "Epoch 10/52\n",
      "24650/24650 [==============================] - 3s 127us/sample - loss: 0.4233 - accuracy: 0.8347\n",
      "Epoch 11/52\n",
      "24650/24650 [==============================] - 3s 103us/sample - loss: 0.3985 - accuracy: 0.8432\n",
      "Epoch 12/52\n",
      "24650/24650 [==============================] - 2s 87us/sample - loss: 0.3828 - accuracy: 0.8503\n",
      "Epoch 13/52\n",
      "24650/24650 [==============================] - 2s 86us/sample - loss: 0.3751 - accuracy: 0.8554\n",
      "Epoch 14/52\n",
      "24650/24650 [==============================] - 2s 87us/sample - loss: 0.3576 - accuracy: 0.8574\n",
      "Epoch 15/52\n",
      "24650/24650 [==============================] - 2s 85us/sample - loss: 0.3393 - accuracy: 0.8673\n",
      "Epoch 16/52\n",
      "24650/24650 [==============================] - 2s 86us/sample - loss: 0.3251 - accuracy: 0.8735\n",
      "Epoch 17/52\n",
      "24650/24650 [==============================] - 2s 88us/sample - loss: 0.3144 - accuracy: 0.8783\n",
      "Epoch 18/52\n",
      "24650/24650 [==============================] - 2s 85us/sample - loss: 0.2973 - accuracy: 0.8852\n",
      "Epoch 19/52\n",
      "24650/24650 [==============================] - 2s 86us/sample - loss: 0.2891 - accuracy: 0.8886\n",
      "Epoch 20/52\n",
      "24650/24650 [==============================] - 2s 88us/sample - loss: 0.2720 - accuracy: 0.8939\n",
      "Epoch 21/52\n",
      "24650/24650 [==============================] - 2s 86us/sample - loss: 0.2709 - accuracy: 0.8967\n",
      "Epoch 22/52\n",
      "24650/24650 [==============================] - 2s 87us/sample - loss: 0.2570 - accuracy: 0.9006\n",
      "Epoch 23/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.2580 - accuracy: 0.9012\n",
      "Epoch 24/52\n",
      "24650/24650 [==============================] - 2s 86us/sample - loss: 0.2390 - accuracy: 0.9087\n",
      "Epoch 25/52\n",
      "24650/24650 [==============================] - 2s 86us/sample - loss: 0.2223 - accuracy: 0.9144\n",
      "Epoch 26/52\n",
      "24650/24650 [==============================] - 2s 86us/sample - loss: 0.2202 - accuracy: 0.9170\n",
      "Epoch 27/52\n",
      "24650/24650 [==============================] - 2s 87us/sample - loss: 0.2016 - accuracy: 0.9248\n",
      "Epoch 28/52\n",
      "24650/24650 [==============================] - 2s 87us/sample - loss: 0.2049 - accuracy: 0.9222\n",
      "Epoch 29/52\n",
      "24650/24650 [==============================] - 2s 88us/sample - loss: 0.1984 - accuracy: 0.9245\n",
      "Epoch 30/52\n",
      "24650/24650 [==============================] - 2s 86us/sample - loss: 0.1992 - accuracy: 0.9248\n",
      "Epoch 31/52\n",
      "24650/24650 [==============================] - 2s 86us/sample - loss: 0.1840 - accuracy: 0.9295\n",
      "Epoch 32/52\n",
      "24650/24650 [==============================] - 2s 86us/sample - loss: 0.1780 - accuracy: 0.9323\n",
      "Epoch 33/52\n",
      "24650/24650 [==============================] - 2s 86us/sample - loss: 0.1703 - accuracy: 0.9370\n",
      "Epoch 34/52\n",
      "24650/24650 [==============================] - 2s 85us/sample - loss: 0.1566 - accuracy: 0.9417\n",
      "Epoch 35/52\n",
      "24650/24650 [==============================] - 2s 86us/sample - loss: 0.1840 - accuracy: 0.9322\n",
      "Epoch 36/52\n",
      "24650/24650 [==============================] - 2s 87us/sample - loss: 0.1454 - accuracy: 0.9454\n",
      "Epoch 37/52\n",
      "24650/24650 [==============================] - 2s 86us/sample - loss: 0.1444 - accuracy: 0.9468\n",
      "Epoch 38/52\n",
      "24650/24650 [==============================] - 3s 112us/sample - loss: 0.1543 - accuracy: 0.9430\n",
      "Epoch 39/52\n",
      "24650/24650 [==============================] - 2s 94us/sample - loss: 0.1409 - accuracy: 0.9481\n",
      "Epoch 40/52\n",
      "24650/24650 [==============================] - 2s 87us/sample - loss: 0.1415 - accuracy: 0.9489\n",
      "Epoch 41/52\n",
      "24650/24650 [==============================] - 2s 81us/sample - loss: 0.1348 - accuracy: 0.9512\n",
      "Epoch 42/52\n",
      "24650/24650 [==============================] - 2s 90us/sample - loss: 0.1210 - accuracy: 0.9561\n",
      "Epoch 43/52\n",
      "24650/24650 [==============================] - 2s 94us/sample - loss: 0.1233 - accuracy: 0.9552\n",
      "Epoch 44/52\n",
      "24650/24650 [==============================] - 2s 93us/sample - loss: 0.1147 - accuracy: 0.9581\n",
      "Epoch 45/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24650/24650 [==============================] - 2s 95us/sample - loss: 0.1320 - accuracy: 0.9513\n",
      "Epoch 46/52\n",
      "24650/24650 [==============================] - 2s 95us/sample - loss: 0.1211 - accuracy: 0.9566\n",
      "Epoch 47/52\n",
      "24650/24650 [==============================] - 2s 98us/sample - loss: 0.1151 - accuracy: 0.9575\n",
      "Epoch 48/52\n",
      "24650/24650 [==============================] - 2s 94us/sample - loss: 0.1129 - accuracy: 0.9591\n",
      "Epoch 49/52\n",
      "24650/24650 [==============================] - 2s 94us/sample - loss: 0.1166 - accuracy: 0.9587\n",
      "Epoch 50/52\n",
      "24650/24650 [==============================] - 2s 95us/sample - loss: 0.1002 - accuracy: 0.9639\n",
      "Epoch 51/52\n",
      "24650/24650 [==============================] - 2s 95us/sample - loss: 0.1034 - accuracy: 0.9625\n",
      "Epoch 52/52\n",
      "24650/24650 [==============================] - 3s 129us/sample - loss: 0.1034 - accuracy: 0.9629\n",
      "2739/2739 [==============================] - 0s 128us/sample - loss: 0.0948 - accuracy: 0.9679\n",
      "Train on 24650 samples\n",
      "Epoch 1/52\n",
      "24650/24650 [==============================] - 4s 174us/sample - loss: 1.0139 - accuracy: 0.5822\n",
      "Epoch 2/52\n",
      "24650/24650 [==============================] - 2s 99us/sample - loss: 0.7272 - accuracy: 0.7072\n",
      "Epoch 3/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.6453 - accuracy: 0.7454\n",
      "Epoch 4/52\n",
      "24650/24650 [==============================] - 2s 87us/sample - loss: 0.5812 - accuracy: 0.7692\n",
      "Epoch 5/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.5428 - accuracy: 0.7858\n",
      "Epoch 6/52\n",
      "24650/24650 [==============================] - 2s 81us/sample - loss: 0.5128 - accuracy: 0.7972\n",
      "Epoch 7/52\n",
      "24650/24650 [==============================] - 2s 82us/sample - loss: 0.4904 - accuracy: 0.8089\n",
      "Epoch 8/52\n",
      "24650/24650 [==============================] - 2s 81us/sample - loss: 0.4683 - accuracy: 0.8165\n",
      "Epoch 9/52\n",
      "24650/24650 [==============================] - 2s 79us/sample - loss: 0.4402 - accuracy: 0.8292\n",
      "Epoch 10/52\n",
      "24650/24650 [==============================] - 2s 80us/sample - loss: 0.4263 - accuracy: 0.8332\n",
      "Epoch 11/52\n",
      "24650/24650 [==============================] - 2s 84us/sample - loss: 0.4126 - accuracy: 0.8391\n",
      "Epoch 12/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.3830 - accuracy: 0.8501\n",
      "Epoch 13/52\n",
      "24650/24650 [==============================] - 2s 78us/sample - loss: 0.3660 - accuracy: 0.8580\n",
      "Epoch 14/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.3516 - accuracy: 0.8640\n",
      "Epoch 15/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.3395 - accuracy: 0.8675\n",
      "Epoch 16/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.3271 - accuracy: 0.8713\n",
      "Epoch 17/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.3212 - accuracy: 0.8743\n",
      "Epoch 18/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.3118 - accuracy: 0.8784\n",
      "Epoch 19/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.2878 - accuracy: 0.8880\n",
      "Epoch 20/52\n",
      "24650/24650 [==============================] - 2s 72us/sample - loss: 0.2825 - accuracy: 0.8925\n",
      "Epoch 21/52\n",
      "24650/24650 [==============================] - 2s 82us/sample - loss: 0.2700 - accuracy: 0.8973\n",
      "Epoch 22/52\n",
      "24650/24650 [==============================] - 2s 79us/sample - loss: 0.2565 - accuracy: 0.9021\n",
      "Epoch 23/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.2571 - accuracy: 0.9013\n",
      "Epoch 24/52\n",
      "24650/24650 [==============================] - 2s 97us/sample - loss: 0.2472 - accuracy: 0.9056\n",
      "Epoch 25/52\n",
      "24650/24650 [==============================] - 3s 120us/sample - loss: 0.2338 - accuracy: 0.9107\n",
      "Epoch 26/52\n",
      "24650/24650 [==============================] - 2s 86us/sample - loss: 0.2309 - accuracy: 0.9105\n",
      "Epoch 27/52\n",
      "24650/24650 [==============================] - 2s 82us/sample - loss: 0.2187 - accuracy: 0.9168\n",
      "Epoch 28/52\n",
      "24650/24650 [==============================] - 2s 81us/sample - loss: 0.2100 - accuracy: 0.9203\n",
      "Epoch 29/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1988 - accuracy: 0.9253\n",
      "Epoch 30/52\n",
      "24650/24650 [==============================] - 2s 81us/sample - loss: 0.1979 - accuracy: 0.9269\n",
      "Epoch 31/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.1868 - accuracy: 0.9285\n",
      "Epoch 32/52\n",
      "24650/24650 [==============================] - 2s 80us/sample - loss: 0.1867 - accuracy: 0.9304\n",
      "Epoch 33/52\n",
      "24650/24650 [==============================] - 2s 92us/sample - loss: 0.1827 - accuracy: 0.9305\n",
      "Epoch 34/52\n",
      "24650/24650 [==============================] - 2s 96us/sample - loss: 0.1706 - accuracy: 0.9382\n",
      "Epoch 35/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.1680 - accuracy: 0.9377\n",
      "Epoch 36/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1670 - accuracy: 0.9375\n",
      "Epoch 37/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1628 - accuracy: 0.9391\n",
      "Epoch 38/52\n",
      "24650/24650 [==============================] - 2s 78us/sample - loss: 0.1578 - accuracy: 0.9425\n",
      "Epoch 39/52\n",
      "24650/24650 [==============================] - 2s 78us/sample - loss: 0.1571 - accuracy: 0.9431\n",
      "Epoch 40/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1437 - accuracy: 0.9458\n",
      "Epoch 41/52\n",
      "24650/24650 [==============================] - 2s 78us/sample - loss: 0.1410 - accuracy: 0.9479\n",
      "Epoch 42/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.1287 - accuracy: 0.9536\n",
      "Epoch 43/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1379 - accuracy: 0.9508\n",
      "Epoch 44/52\n",
      "24650/24650 [==============================] - 2s 78us/sample - loss: 0.1209 - accuracy: 0.9558\n",
      "Epoch 45/52\n",
      "24650/24650 [==============================] - 2s 78us/sample - loss: 0.1293 - accuracy: 0.9532\n",
      "Epoch 46/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1190 - accuracy: 0.9562\n",
      "Epoch 47/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.1207 - accuracy: 0.9556\n",
      "Epoch 48/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1124 - accuracy: 0.9582\n",
      "Epoch 49/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1203 - accuracy: 0.9567\n",
      "Epoch 50/52\n",
      "24650/24650 [==============================] - 2s 61us/sample - loss: 0.1218 - accuracy: 0.9569\n",
      "Epoch 51/52\n",
      "24650/24650 [==============================] - 2s 69us/sample - loss: 0.1053 - accuracy: 0.9618\n",
      "Epoch 52/52\n",
      "24650/24650 [==============================] - 2s 71us/sample - loss: 0.1003 - accuracy: 0.9637\n",
      "2739/2739 [==============================] - 0s 87us/sample - loss: 0.0996 - accuracy: 0.9668\n",
      "Train on 24650 samples\n",
      "Epoch 1/52\n",
      "24650/24650 [==============================] - 2s 93us/sample - loss: 1.0419 - accuracy: 0.5739\n",
      "Epoch 2/52\n",
      "24650/24650 [==============================] - 1s 59us/sample - loss: 0.7392 - accuracy: 0.7011\n",
      "Epoch 3/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.6541 - accuracy: 0.7400\n",
      "Epoch 4/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.6026 - accuracy: 0.7575\n",
      "Epoch 5/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.5580 - accuracy: 0.7796\n",
      "Epoch 6/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.5322 - accuracy: 0.7888\n",
      "Epoch 7/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.4993 - accuracy: 0.8029\n",
      "Epoch 8/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.4796 - accuracy: 0.8118\n",
      "Epoch 9/52\n",
      "24650/24650 [==============================] - 2s 78us/sample - loss: 0.4478 - accuracy: 0.8252\n",
      "Epoch 10/52\n",
      "24650/24650 [==============================] - 2s 80us/sample - loss: 0.4304 - accuracy: 0.8327\n",
      "Epoch 11/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.4123 - accuracy: 0.8387\n",
      "Epoch 12/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.3922 - accuracy: 0.8477\n",
      "Epoch 13/52\n",
      "24650/24650 [==============================] - 2s 79us/sample - loss: 0.3740 - accuracy: 0.8542\n",
      "Epoch 14/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.3702 - accuracy: 0.8549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/52\n",
      "24650/24650 [==============================] - 2s 71us/sample - loss: 0.3582 - accuracy: 0.8609\n",
      "Epoch 16/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.3339 - accuracy: 0.8699\n",
      "Epoch 17/52\n",
      "24650/24650 [==============================] - 2s 71us/sample - loss: 0.3221 - accuracy: 0.8763\n",
      "Epoch 18/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.3110 - accuracy: 0.8798\n",
      "Epoch 19/52\n",
      "24650/24650 [==============================] - 2s 67us/sample - loss: 0.2983 - accuracy: 0.8860\n",
      "Epoch 20/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.2818 - accuracy: 0.8915\n",
      "Epoch 21/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.2812 - accuracy: 0.8918\n",
      "Epoch 22/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.2654 - accuracy: 0.8977\n",
      "Epoch 23/52\n",
      "24650/24650 [==============================] - 2s 72us/sample - loss: 0.2622 - accuracy: 0.9018\n",
      "Epoch 24/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.2542 - accuracy: 0.9015\n",
      "Epoch 25/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.2399 - accuracy: 0.9079\n",
      "Epoch 26/52\n",
      "24650/24650 [==============================] - 2s 72us/sample - loss: 0.2286 - accuracy: 0.9151\n",
      "Epoch 27/52\n",
      "24650/24650 [==============================] - 2s 72us/sample - loss: 0.2270 - accuracy: 0.9125\n",
      "Epoch 28/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.2127 - accuracy: 0.9187\n",
      "Epoch 29/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.2092 - accuracy: 0.9210\n",
      "Epoch 30/52\n",
      "24650/24650 [==============================] - 2s 70us/sample - loss: 0.2034 - accuracy: 0.9229\n",
      "Epoch 31/52\n",
      "24650/24650 [==============================] - 2s 72us/sample - loss: 0.1907 - accuracy: 0.9298\n",
      "Epoch 32/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.1836 - accuracy: 0.9295\n",
      "Epoch 33/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.1765 - accuracy: 0.9340\n",
      "Epoch 34/52\n",
      "24650/24650 [==============================] - 2s 66us/sample - loss: 0.1851 - accuracy: 0.9318\n",
      "Epoch 35/52\n",
      "24650/24650 [==============================] - 2s 72us/sample - loss: 0.1610 - accuracy: 0.9386\n",
      "Epoch 36/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.1601 - accuracy: 0.9396\n",
      "Epoch 37/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1583 - accuracy: 0.9414\n",
      "Epoch 38/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.1478 - accuracy: 0.9447\n",
      "Epoch 39/52\n",
      "24650/24650 [==============================] - 2s 72us/sample - loss: 0.1480 - accuracy: 0.9459\n",
      "Epoch 40/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1431 - accuracy: 0.9470\n",
      "Epoch 41/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1344 - accuracy: 0.9504\n",
      "Epoch 42/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1438 - accuracy: 0.9463\n",
      "Epoch 43/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.1385 - accuracy: 0.9507\n",
      "Epoch 44/52\n",
      "24650/24650 [==============================] - 2s 71us/sample - loss: 0.1243 - accuracy: 0.9553\n",
      "Epoch 45/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.1152 - accuracy: 0.9574\n",
      "Epoch 46/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.1249 - accuracy: 0.9552\n",
      "Epoch 47/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.1194 - accuracy: 0.9576\n",
      "Epoch 48/52\n",
      "24650/24650 [==============================] - 2s 72us/sample - loss: 0.1123 - accuracy: 0.9596\n",
      "Epoch 49/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1067 - accuracy: 0.9608\n",
      "Epoch 50/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1115 - accuracy: 0.9604\n",
      "Epoch 51/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.1058 - accuracy: 0.9611\n",
      "Epoch 52/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.1010 - accuracy: 0.9639\n",
      "2739/2739 [==============================] - 0s 111us/sample - loss: 0.0771 - accuracy: 0.9763\n",
      "Train on 24650 samples\n",
      "Epoch 1/52\n",
      "24650/24650 [==============================] - 3s 117us/sample - loss: 1.0282 - accuracy: 0.5712\n",
      "Epoch 2/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.7389 - accuracy: 0.7062\n",
      "Epoch 3/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.6350 - accuracy: 0.7464\n",
      "Epoch 4/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.5890 - accuracy: 0.7664\n",
      "Epoch 5/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.5555 - accuracy: 0.7794\n",
      "Epoch 6/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.5154 - accuracy: 0.7970\n",
      "Epoch 7/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.4977 - accuracy: 0.8031\n",
      "Epoch 8/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.4704 - accuracy: 0.8144\n",
      "Epoch 9/52\n",
      "24650/24650 [==============================] - 2s 69us/sample - loss: 0.4511 - accuracy: 0.8223\n",
      "Epoch 10/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.4257 - accuracy: 0.8329\n",
      "Epoch 11/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.4048 - accuracy: 0.8409\n",
      "Epoch 12/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.3852 - accuracy: 0.8471\n",
      "Epoch 13/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.3742 - accuracy: 0.8533\n",
      "Epoch 14/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.3603 - accuracy: 0.8596\n",
      "Epoch 15/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.3484 - accuracy: 0.8630\n",
      "Epoch 16/52\n",
      "24650/24650 [==============================] - 2s 70us/sample - loss: 0.3327 - accuracy: 0.8701\n",
      "Epoch 17/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.3217 - accuracy: 0.8727\n",
      "Epoch 18/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.3071 - accuracy: 0.8815\n",
      "Epoch 19/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.3011 - accuracy: 0.8820\n",
      "Epoch 20/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.2793 - accuracy: 0.8909\n",
      "Epoch 21/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.2739 - accuracy: 0.8943\n",
      "Epoch 22/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.2617 - accuracy: 0.8978\n",
      "Epoch 23/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.2600 - accuracy: 0.8992\n",
      "Epoch 24/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.2491 - accuracy: 0.9060\n",
      "Epoch 25/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.2386 - accuracy: 0.9073\n",
      "Epoch 26/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.2318 - accuracy: 0.9126\n",
      "Epoch 27/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.2229 - accuracy: 0.9147\n",
      "Epoch 28/52\n",
      "24650/24650 [==============================] - 2s 72us/sample - loss: 0.2099 - accuracy: 0.9208\n",
      "Epoch 29/52\n",
      "24650/24650 [==============================] - 2s 70us/sample - loss: 0.2103 - accuracy: 0.9210\n",
      "Epoch 30/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1931 - accuracy: 0.9275\n",
      "Epoch 31/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.1912 - accuracy: 0.9280\n",
      "Epoch 32/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1897 - accuracy: 0.9286\n",
      "Epoch 33/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1707 - accuracy: 0.9357\n",
      "Epoch 34/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1775 - accuracy: 0.9340\n",
      "Epoch 35/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1661 - accuracy: 0.9375\n",
      "Epoch 36/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1592 - accuracy: 0.9407\n",
      "Epoch 37/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1659 - accuracy: 0.9370\n",
      "Epoch 38/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1448 - accuracy: 0.9465\n",
      "Epoch 39/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.1497 - accuracy: 0.9439\n",
      "Epoch 40/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.1610 - accuracy: 0.9398\n",
      "Epoch 41/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1368 - accuracy: 0.9502\n",
      "Epoch 42/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.1487 - accuracy: 0.9434\n",
      "Epoch 43/52\n",
      "24650/24650 [==============================] - 2s 67us/sample - loss: 0.1259 - accuracy: 0.9532\n",
      "Epoch 44/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.1234 - accuracy: 0.9554\n",
      "Epoch 45/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1251 - accuracy: 0.9531\n",
      "Epoch 46/52\n",
      "24650/24650 [==============================] - 2s 79us/sample - loss: 0.1304 - accuracy: 0.9511\n",
      "Epoch 47/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.1227 - accuracy: 0.9546\n",
      "Epoch 48/52\n",
      "24650/24650 [==============================] - 2s 71us/sample - loss: 0.1151 - accuracy: 0.9591\n",
      "Epoch 49/52\n",
      "24650/24650 [==============================] - 2s 72us/sample - loss: 0.1080 - accuracy: 0.9600\n",
      "Epoch 50/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.1099 - accuracy: 0.9598\n",
      "Epoch 51/52\n",
      "24650/24650 [==============================] - 2s 71us/sample - loss: 0.1039 - accuracy: 0.9605\n",
      "Epoch 52/52\n",
      "24650/24650 [==============================] - 2s 89us/sample - loss: 0.1086 - accuracy: 0.9607\n",
      "2739/2739 [==============================] - 0s 110us/sample - loss: 0.0899 - accuracy: 0.9668\n",
      "Train on 24650 samples\n",
      "Epoch 1/52\n",
      "24650/24650 [==============================] - 3s 129us/sample - loss: 1.0248 - accuracy: 0.5722\n",
      "Epoch 2/52\n",
      "24650/24650 [==============================] - 2s 94us/sample - loss: 0.7418 - accuracy: 0.7002\n",
      "Epoch 3/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.6415 - accuracy: 0.7428\n",
      "Epoch 4/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.5948 - accuracy: 0.7650\n",
      "Epoch 5/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.5419 - accuracy: 0.7876\n",
      "Epoch 6/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.5187 - accuracy: 0.7962\n",
      "Epoch 7/52\n",
      "24650/24650 [==============================] - 2s 72us/sample - loss: 0.4917 - accuracy: 0.8051\n",
      "Epoch 8/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.4726 - accuracy: 0.8142\n",
      "Epoch 9/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.4553 - accuracy: 0.8205\n",
      "Epoch 10/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.4236 - accuracy: 0.8362\n",
      "Epoch 11/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.4173 - accuracy: 0.8378\n",
      "Epoch 12/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.3906 - accuracy: 0.8481\n",
      "Epoch 13/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.3746 - accuracy: 0.8515\n",
      "Epoch 14/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.3605 - accuracy: 0.8596\n",
      "Epoch 15/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.3473 - accuracy: 0.8667\n",
      "Epoch 16/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.3417 - accuracy: 0.8674\n",
      "Epoch 17/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.3253 - accuracy: 0.8732\n",
      "Epoch 18/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.3051 - accuracy: 0.8820\n",
      "Epoch 19/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.2921 - accuracy: 0.8866\n",
      "Epoch 20/52\n",
      "24650/24650 [==============================] - 2s 74us/sample - loss: 0.2888 - accuracy: 0.8900\n",
      "Epoch 21/52\n",
      "24650/24650 [==============================] - 2s 76us/sample - loss: 0.2779 - accuracy: 0.8911\n",
      "Epoch 22/52\n",
      "24650/24650 [==============================] - 2s 73us/sample - loss: 0.2598 - accuracy: 0.9030\n",
      "Epoch 23/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.2660 - accuracy: 0.8985\n",
      "Epoch 24/52\n",
      "24650/24650 [==============================] - 2s 75us/sample - loss: 0.2506 - accuracy: 0.9030\n",
      "Epoch 25/52\n",
      "24650/24650 [==============================] - 2s 77us/sample - loss: 0.2388 - accuracy: 0.9087\n",
      "Epoch 26/52\n",
      "24650/24650 [==============================] - 3s 109us/sample - loss: 0.2328 - accuracy: 0.9129\n",
      "Epoch 27/52\n",
      "24650/24650 [==============================] - 3s 127us/sample - loss: 0.2209 - accuracy: 0.9162\n",
      "Epoch 28/52\n",
      "24650/24650 [==============================] - 4s 150us/sample - loss: 0.2143 - accuracy: 0.9196\n",
      "Epoch 29/52\n",
      "24650/24650 [==============================] - 4s 172us/sample - loss: 0.2049 - accuracy: 0.9233\n",
      "Epoch 30/52\n",
      "24650/24650 [==============================] - 4s 148us/sample - loss: 0.2038 - accuracy: 0.9228\n",
      "Epoch 31/52\n",
      "24650/24650 [==============================] - 4s 172us/sample - loss: 0.1888 - accuracy: 0.9301\n",
      "Epoch 32/52\n",
      "24650/24650 [==============================] - 4s 173us/sample - loss: 0.1857 - accuracy: 0.9294\n",
      "Epoch 33/52\n",
      "24650/24650 [==============================] - 4s 174us/sample - loss: 0.1761 - accuracy: 0.9344\n",
      "Epoch 34/52\n",
      "24650/24650 [==============================] - 4s 160us/sample - loss: 0.1665 - accuracy: 0.9378\n",
      "Epoch 35/52\n",
      "24650/24650 [==============================] - 4s 160us/sample - loss: 0.1653 - accuracy: 0.9392\n",
      "Epoch 36/52\n",
      "24650/24650 [==============================] - 4s 174us/sample - loss: 0.1663 - accuracy: 0.9389\n",
      "Epoch 37/52\n",
      "24650/24650 [==============================] - 4s 170us/sample - loss: 0.1485 - accuracy: 0.9465\n",
      "Epoch 38/52\n",
      "24650/24650 [==============================] - 4s 172us/sample - loss: 0.1763 - accuracy: 0.9357 - los\n",
      "Epoch 39/52\n",
      "24650/24650 [==============================] - 4s 161us/sample - loss: 0.1468 - accuracy: 0.9468\n",
      "Epoch 40/52\n",
      "24650/24650 [==============================] - 4s 146us/sample - loss: 0.1410 - accuracy: 0.9482\n",
      "Epoch 41/52\n",
      "24650/24650 [==============================] - 3s 138us/sample - loss: 0.1375 - accuracy: 0.9495\n",
      "Epoch 42/52\n",
      "24650/24650 [==============================] - 3s 104us/sample - loss: 0.1382 - accuracy: 0.9486\n",
      "Epoch 43/52\n",
      "24650/24650 [==============================] - 3s 104us/sample - loss: 0.1312 - accuracy: 0.9517\n",
      "Epoch 44/52\n",
      "24650/24650 [==============================] - 2s 98us/sample - loss: 0.1264 - accuracy: 0.9532\n",
      "Epoch 45/52\n",
      "24650/24650 [==============================] - 2s 97us/sample - loss: 0.1258 - accuracy: 0.9542\n",
      "Epoch 46/52\n",
      "24650/24650 [==============================] - 3s 104us/sample - loss: 0.1266 - accuracy: 0.9544\n",
      "Epoch 47/52\n",
      "24650/24650 [==============================] - 3s 106us/sample - loss: 0.1171 - accuracy: 0.9580\n",
      "Epoch 48/52\n",
      "24650/24650 [==============================] - 3s 105us/sample - loss: 0.1161 - accuracy: 0.9591\n",
      "Epoch 49/52\n",
      "24650/24650 [==============================] - 3s 105us/sample - loss: 0.1174 - accuracy: 0.9592\n",
      "Epoch 50/52\n",
      "24650/24650 [==============================] - 3s 102us/sample - loss: 0.1124 - accuracy: 0.9591\n",
      "Epoch 51/52\n",
      "24650/24650 [==============================] - 2s 99us/sample - loss: 0.1082 - accuracy: 0.9628\n",
      "Epoch 52/52\n",
      "24650/24650 [==============================] - 3s 103us/sample - loss: 0.1040 - accuracy: 0.9617\n",
      "2739/2739 [==============================] - 0s 178us/sample - loss: 0.0884 - accuracy: 0.9715\n",
      "Train on 24650 samples\n",
      "Epoch 1/52\n",
      "24650/24650 [==============================] - 5s 191us/sample - loss: 1.0202 - accuracy: 0.5785\n",
      "Epoch 2/52\n",
      "24650/24650 [==============================] - 3s 111us/sample - loss: 0.7446 - accuracy: 0.6970\n",
      "Epoch 3/52\n",
      "24650/24650 [==============================] - 3s 142us/sample - loss: 0.6464 - accuracy: 0.7422\n",
      "Epoch 4/52\n",
      "24650/24650 [==============================] - 4s 148us/sample - loss: 0.5947 - accuracy: 0.7645 - l\n",
      "Epoch 5/52\n",
      "24650/24650 [==============================] - 3s 138us/sample - loss: 0.5569 - accuracy: 0.7802\n",
      "Epoch 6/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24650/24650 [==============================] - 3s 102us/sample - loss: 0.5282 - accuracy: 0.7915\n",
      "Epoch 7/52\n",
      "24650/24650 [==============================] - 3s 102us/sample - loss: 0.4928 - accuracy: 0.8045\n",
      "Epoch 8/52\n",
      "24650/24650 [==============================] - 2s 92us/sample - loss: 0.4775 - accuracy: 0.8104\n",
      "Epoch 9/52\n",
      "24650/24650 [==============================] - 3s 102us/sample - loss: 0.4499 - accuracy: 0.8210\n",
      "Epoch 10/52\n",
      "24650/24650 [==============================] - 3s 103us/sample - loss: 0.4341 - accuracy: 0.8303\n",
      "Epoch 11/52\n",
      "24650/24650 [==============================] - 3s 102us/sample - loss: 0.4039 - accuracy: 0.8429\n",
      "Epoch 12/52\n",
      "24650/24650 [==============================] - 3s 102us/sample - loss: 0.4035 - accuracy: 0.8437\n",
      "Epoch 13/52\n",
      "24650/24650 [==============================] - 3s 102us/sample - loss: 0.3700 - accuracy: 0.8548\n",
      "Epoch 14/52\n",
      "24650/24650 [==============================] - 3s 102us/sample - loss: 0.3587 - accuracy: 0.8594\n",
      "Epoch 15/52\n",
      "24650/24650 [==============================] - 3s 102us/sample - loss: 0.3462 - accuracy: 0.8658\n",
      "Epoch 16/52\n",
      "24650/24650 [==============================] - 3s 103us/sample - loss: 0.3318 - accuracy: 0.8714\n",
      "Epoch 17/52\n",
      "24650/24650 [==============================] - 3s 102us/sample - loss: 0.3231 - accuracy: 0.8742\n",
      "Epoch 18/52\n",
      "24650/24650 [==============================] - 3s 116us/sample - loss: 0.3152 - accuracy: 0.8783\n",
      "Epoch 19/52\n",
      "24650/24650 [==============================] - 4s 144us/sample - loss: 0.3001 - accuracy: 0.8841\n",
      "Epoch 20/52\n",
      "24650/24650 [==============================] - 4s 142us/sample - loss: 0.2890 - accuracy: 0.8901\n",
      "Epoch 21/52\n",
      "24650/24650 [==============================] - 4s 144us/sample - loss: 0.2782 - accuracy: 0.8934\n",
      "Epoch 22/52\n",
      "24650/24650 [==============================] - 4s 143us/sample - loss: 0.2576 - accuracy: 0.9025\n",
      "Epoch 23/52\n",
      "24650/24650 [==============================] - 4s 143us/sample - loss: 0.2587 - accuracy: 0.9016\n",
      "Epoch 24/52\n",
      "24650/24650 [==============================] - 3s 142us/sample - loss: 0.2520 - accuracy: 0.9039\n",
      "Epoch 25/52\n",
      "24650/24650 [==============================] - 3s 131us/sample - loss: 0.2393 - accuracy: 0.9098\n",
      "Epoch 26/52\n",
      "24650/24650 [==============================] - 4s 144us/sample - loss: 0.2279 - accuracy: 0.9132\n",
      "Epoch 27/52\n",
      "24650/24650 [==============================] - 4s 144us/sample - loss: 0.2357 - accuracy: 0.9086\n",
      "Epoch 28/52\n",
      "24650/24650 [==============================] - 3s 125us/sample - loss: 0.2134 - accuracy: 0.9189\n",
      "Epoch 29/52\n",
      "24650/24650 [==============================] - 3s 137us/sample - loss: 0.2042 - accuracy: 0.9236\n",
      "Epoch 30/52\n",
      "24650/24650 [==============================] - 4s 147us/sample - loss: 0.2045 - accuracy: 0.9230\n",
      "Epoch 31/52\n",
      "24650/24650 [==============================] - 3s 130us/sample - loss: 0.1816 - accuracy: 0.9321\n",
      "Epoch 32/52\n",
      "24650/24650 [==============================] - 4s 144us/sample - loss: 0.1880 - accuracy: 0.9288\n",
      "Epoch 33/52\n",
      "24650/24650 [==============================] - 4s 143us/sample - loss: 0.1726 - accuracy: 0.9353\n",
      "Epoch 34/52\n",
      "24650/24650 [==============================] - 4s 144us/sample - loss: 0.1710 - accuracy: 0.9371\n",
      "Epoch 35/52\n",
      "24650/24650 [==============================] - 4s 144us/sample - loss: 0.1722 - accuracy: 0.9359\n",
      "Epoch 36/52\n",
      "24650/24650 [==============================] - 4s 144us/sample - loss: 0.1528 - accuracy: 0.9437\n",
      "Epoch 37/52\n",
      "24650/24650 [==============================] - 4s 144us/sample - loss: 0.1504 - accuracy: 0.9441\n",
      "Epoch 38/52\n",
      "24650/24650 [==============================] - 4s 145us/sample - loss: 0.1520 - accuracy: 0.9452\n",
      "Epoch 39/52\n",
      "24650/24650 [==============================] - 4s 144us/sample - loss: 0.1429 - accuracy: 0.9469\n",
      "Epoch 40/52\n",
      "24650/24650 [==============================] - 2s 100us/sample - loss: 0.1446 - accuracy: 0.9466\n",
      "Epoch 41/52\n",
      "24650/24650 [==============================] - 2s 100us/sample - loss: 0.1474 - accuracy: 0.9455\n",
      "Epoch 42/52\n",
      "24650/24650 [==============================] - 2s 99us/sample - loss: 0.1221 - accuracy: 0.9552\n",
      "Epoch 43/52\n",
      "24650/24650 [==============================] - 2s 100us/sample - loss: 0.1305 - accuracy: 0.9528\n",
      "Epoch 44/52\n",
      "24650/24650 [==============================] - 2s 93us/sample - loss: 0.1169 - accuracy: 0.9581\n",
      "Epoch 45/52\n",
      "24650/24650 [==============================] - 2s 92us/sample - loss: 0.1303 - accuracy: 0.9527\n",
      "Epoch 46/52\n",
      "24650/24650 [==============================] - 2s 100us/sample - loss: 0.1136 - accuracy: 0.9593\n",
      "Epoch 47/52\n",
      "24650/24650 [==============================] - 2s 99us/sample - loss: 0.1193 - accuracy: 0.9571\n",
      "Epoch 48/52\n",
      "24650/24650 [==============================] - 2s 99us/sample - loss: 0.1076 - accuracy: 0.9622\n",
      "Epoch 49/52\n",
      "24650/24650 [==============================] - 2s 99us/sample - loss: 0.1175 - accuracy: 0.9569\n",
      "Epoch 50/52\n",
      "24650/24650 [==============================] - 2s 99us/sample - loss: 0.1132 - accuracy: 0.9595\n",
      "Epoch 51/52\n",
      "24650/24650 [==============================] - 2s 99us/sample - loss: 0.0968 - accuracy: 0.9654\n",
      "Epoch 52/52\n",
      "24650/24650 [==============================] - 2s 99us/sample - loss: 0.1096 - accuracy: 0.9609\n",
      "2739/2739 [==============================] - 0s 125us/sample - loss: 0.1245 - accuracy: 0.9533\n",
      "Train on 24650 samples\n",
      "Epoch 1/52\n",
      "24650/24650 [==============================] - 3s 116us/sample - loss: 1.0246 - accuracy: 0.5765\n",
      "Epoch 2/52\n",
      "24650/24650 [==============================] - 4s 145us/sample - loss: 0.7357 - accuracy: 0.7035\n",
      "Epoch 3/52\n",
      "24650/24650 [==============================] - 3s 140us/sample - loss: 0.6552 - accuracy: 0.7404\n",
      "Epoch 4/52\n",
      "24650/24650 [==============================] - 4s 146us/sample - loss: 0.5947 - accuracy: 0.7623\n",
      "Epoch 5/52\n",
      "24650/24650 [==============================] - 4s 144us/sample - loss: 0.5563 - accuracy: 0.7800\n",
      "Epoch 6/52\n",
      "24650/24650 [==============================] - 4s 145us/sample - loss: 0.5176 - accuracy: 0.7929\n",
      "Epoch 7/52\n",
      "24650/24650 [==============================] - 4s 145us/sample - loss: 0.5021 - accuracy: 0.8002\n",
      "Epoch 8/52\n",
      "24650/24650 [==============================] - 4s 144us/sample - loss: 0.4676 - accuracy: 0.8139\n",
      "Epoch 9/52\n",
      "24650/24650 [==============================] - 4s 146us/sample - loss: 0.4432 - accuracy: 0.8247\n",
      "Epoch 10/52\n",
      "24650/24650 [==============================] - 3s 137us/sample - loss: 0.4256 - accuracy: 0.8340\n",
      "Epoch 11/52\n",
      "24650/24650 [==============================] - 3s 102us/sample - loss: 0.4094 - accuracy: 0.8398\n",
      "Epoch 12/52\n",
      "24650/24650 [==============================] - 4s 145us/sample - loss: 0.3969 - accuracy: 0.8460\n",
      "Epoch 13/52\n",
      "24650/24650 [==============================] - 4s 145us/sample - loss: 0.3772 - accuracy: 0.8522\n",
      "Epoch 14/52\n",
      "24650/24650 [==============================] - 4s 145us/sample - loss: 0.3641 - accuracy: 0.8579\n",
      "Epoch 15/52\n",
      "24650/24650 [==============================] - 3s 124us/sample - loss: 0.3451 - accuracy: 0.8652\n",
      "Epoch 16/52\n",
      "24650/24650 [==============================] - 4s 145us/sample - loss: 0.3315 - accuracy: 0.8702\n",
      "Epoch 17/52\n",
      "24650/24650 [==============================] - 4s 146us/sample - loss: 0.3247 - accuracy: 0.8746\n",
      "Epoch 18/52\n",
      "24650/24650 [==============================] - 4s 145us/sample - loss: 0.3163 - accuracy: 0.8770\n",
      "Epoch 19/52\n",
      "24650/24650 [==============================] - 4s 145us/sample - loss: 0.2975 - accuracy: 0.8859\n",
      "Epoch 20/52\n",
      "24650/24650 [==============================] - 4s 145us/sample - loss: 0.2856 - accuracy: 0.8880\n",
      "Epoch 21/52\n",
      "24650/24650 [==============================] - 4s 145us/sample - loss: 0.2704 - accuracy: 0.8962\n",
      "Epoch 22/52\n",
      "24650/24650 [==============================] - 4s 145us/sample - loss: 0.2677 - accuracy: 0.8966\n",
      "Epoch 23/52\n",
      "24650/24650 [==============================] - 3s 136us/sample - loss: 0.2476 - accuracy: 0.9053\n",
      "Epoch 24/52\n",
      "24650/24650 [==============================] - 4s 144us/sample - loss: 0.2580 - accuracy: 0.9017\n",
      "Epoch 25/52\n",
      "24650/24650 [==============================] - 4s 146us/sample - loss: 0.2377 - accuracy: 0.9108\n",
      "Epoch 26/52\n",
      "24650/24650 [==============================] - 3s 141us/sample - loss: 0.2212 - accuracy: 0.9162\n",
      "Epoch 27/52\n",
      "24650/24650 [==============================] - 3s 109us/sample - loss: 0.2114 - accuracy: 0.9196\n",
      "Epoch 28/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24650/24650 [==============================] - 3s 129us/sample - loss: 0.2080 - accuracy: 0.9215\n",
      "Epoch 29/52\n",
      "24650/24650 [==============================] - 3s 103us/sample - loss: 0.2124 - accuracy: 0.9198\n",
      "Epoch 30/52\n",
      "24650/24650 [==============================] - 4s 157us/sample - loss: 0.2004 - accuracy: 0.9244\n",
      "Epoch 31/52\n",
      "24650/24650 [==============================] - 4s 159us/sample - loss: 0.1923 - accuracy: 0.9279\n",
      "Epoch 32/52\n",
      "24650/24650 [==============================] - 4s 155us/sample - loss: 0.1847 - accuracy: 0.9297\n",
      "Epoch 33/52\n",
      "24650/24650 [==============================] - 4s 152us/sample - loss: 0.1791 - accuracy: 0.9327\n",
      "Epoch 34/52\n",
      "24650/24650 [==============================] - 4s 159us/sample - loss: 0.1701 - accuracy: 0.9378\n",
      "Epoch 35/52\n",
      "24650/24650 [==============================] - 4s 154us/sample - loss: 0.1593 - accuracy: 0.9411\n",
      "Epoch 36/52\n",
      "24650/24650 [==============================] - 4s 156us/sample - loss: 0.1545 - accuracy: 0.9426\n",
      "Epoch 37/52\n",
      "24650/24650 [==============================] - 4s 155us/sample - loss: 0.1527 - accuracy: 0.9437\n",
      "Epoch 38/52\n",
      "24650/24650 [==============================] - 4s 154us/sample - loss: 0.1463 - accuracy: 0.9464\n",
      "Epoch 39/52\n",
      "24650/24650 [==============================] - 4s 154us/sample - loss: 0.1501 - accuracy: 0.9453\n",
      "Epoch 40/52\n",
      "24650/24650 [==============================] - 4s 156us/sample - loss: 0.1373 - accuracy: 0.9491\n",
      "Epoch 41/52\n",
      "24650/24650 [==============================] - 4s 154us/sample - loss: 0.1312 - accuracy: 0.9516\n",
      "Epoch 42/52\n",
      "24650/24650 [==============================] - 4s 148us/sample - loss: 0.1383 - accuracy: 0.9490\n",
      "Epoch 43/52\n",
      "24650/24650 [==============================] - 3s 104us/sample - loss: 0.1341 - accuracy: 0.9523\n",
      "Epoch 44/52\n",
      "24650/24650 [==============================] - 3s 111us/sample - loss: 0.1122 - accuracy: 0.9587\n",
      "Epoch 45/52\n",
      "24650/24650 [==============================] - 4s 159us/sample - loss: 0.1258 - accuracy: 0.9540\n",
      "Epoch 46/52\n",
      "24650/24650 [==============================] - 4s 143us/sample - loss: 0.1278 - accuracy: 0.9530\n",
      "Epoch 47/52\n",
      "24650/24650 [==============================] - 4s 164us/sample - loss: 0.1135 - accuracy: 0.9605\n",
      "Epoch 48/52\n",
      "24650/24650 [==============================] - 4s 159us/sample - loss: 0.1092 - accuracy: 0.9621\n",
      "Epoch 49/52\n",
      "24650/24650 [==============================] - 2s 93us/sample - loss: 0.1159 - accuracy: 0.9589\n",
      "Epoch 50/52\n",
      "24650/24650 [==============================] - 2s 92us/sample - loss: 0.1066 - accuracy: 0.9600\n",
      "Epoch 51/52\n",
      "24650/24650 [==============================] - 2s 92us/sample - loss: 0.1019 - accuracy: 0.9636\n",
      "Epoch 52/52\n",
      "24650/24650 [==============================] - 2s 91us/sample - loss: 0.0933 - accuracy: 0.9667\n",
      "2739/2739 [==============================] - 0s 119us/sample - loss: 0.1419 - accuracy: 0.9522\n",
      "Train on 24651 samples\n",
      "Epoch 1/52\n",
      "24651/24651 [==============================] - 5s 207us/sample - loss: 1.0398 - accuracy: 0.5676\n",
      "Epoch 2/52\n",
      "24651/24651 [==============================] - 4s 158us/sample - loss: 0.7440 - accuracy: 0.6981\n",
      "Epoch 3/52\n",
      "24651/24651 [==============================] - 4s 159us/sample - loss: 0.6553 - accuracy: 0.7368\n",
      "Epoch 4/52\n",
      "24651/24651 [==============================] - 3s 112us/sample - loss: 0.5977 - accuracy: 0.7633\n",
      "Epoch 5/52\n",
      "24651/24651 [==============================] - 3s 103us/sample - loss: 0.5577 - accuracy: 0.7764\n",
      "Epoch 6/52\n",
      "24651/24651 [==============================] - 3s 104us/sample - loss: 0.5212 - accuracy: 0.7929\n",
      "Epoch 7/52\n",
      "24651/24651 [==============================] - 3s 103us/sample - loss: 0.5026 - accuracy: 0.8017\n",
      "Epoch 8/52\n",
      "24651/24651 [==============================] - 3s 103us/sample - loss: 0.4724 - accuracy: 0.8133\n",
      "Epoch 9/52\n",
      "24651/24651 [==============================] - 3s 103us/sample - loss: 0.4560 - accuracy: 0.8185\n",
      "Epoch 10/52\n",
      "24651/24651 [==============================] - 3s 104us/sample - loss: 0.4391 - accuracy: 0.8228\n",
      "Epoch 11/52\n",
      "24651/24651 [==============================] - 3s 104us/sample - loss: 0.4037 - accuracy: 0.8402\n",
      "Epoch 12/52\n",
      "24651/24651 [==============================] - 3s 103us/sample - loss: 0.3895 - accuracy: 0.8472\n",
      "Epoch 13/52\n",
      "24651/24651 [==============================] - 3s 103us/sample - loss: 0.3861 - accuracy: 0.8481\n",
      "Epoch 14/52\n",
      "24651/24651 [==============================] - 3s 103us/sample - loss: 0.3614 - accuracy: 0.8602\n",
      "Epoch 15/52\n",
      "24651/24651 [==============================] - 3s 104us/sample - loss: 0.3453 - accuracy: 0.8657\n",
      "Epoch 16/52\n",
      "24651/24651 [==============================] - 3s 104us/sample - loss: 0.3341 - accuracy: 0.8717\n",
      "Epoch 17/52\n",
      "24651/24651 [==============================] - 3s 103us/sample - loss: 0.3250 - accuracy: 0.8740\n",
      "Epoch 18/52\n",
      "24651/24651 [==============================] - 3s 104us/sample - loss: 0.3076 - accuracy: 0.8805\n",
      "Epoch 19/52\n",
      "24651/24651 [==============================] - 3s 103us/sample - loss: 0.2953 - accuracy: 0.8858\n",
      "Epoch 20/52\n",
      "24651/24651 [==============================] - 3s 104us/sample - loss: 0.2833 - accuracy: 0.8878\n",
      "Epoch 21/52\n",
      "24651/24651 [==============================] - 3s 104us/sample - loss: 0.2733 - accuracy: 0.8932\n",
      "Epoch 22/52\n",
      "24651/24651 [==============================] - 3s 103us/sample - loss: 0.2619 - accuracy: 0.8993\n",
      "Epoch 23/52\n",
      "24651/24651 [==============================] - 3s 133us/sample - loss: 0.2470 - accuracy: 0.9051\n",
      "Epoch 24/52\n",
      "24651/24651 [==============================] - 4s 160us/sample - loss: 0.2500 - accuracy: 0.9042\n",
      "Epoch 25/52\n",
      "24651/24651 [==============================] - 2s 78us/sample - loss: 0.2317 - accuracy: 0.9101\n",
      "Epoch 26/52\n",
      "24651/24651 [==============================] - 2s 75us/sample - loss: 0.2217 - accuracy: 0.9169\n",
      "Epoch 27/52\n",
      "24651/24651 [==============================] - 2s 72us/sample - loss: 0.2216 - accuracy: 0.9163\n",
      "Epoch 28/52\n",
      "24651/24651 [==============================] - 2s 75us/sample - loss: 0.2084 - accuracy: 0.9212\n",
      "Epoch 29/52\n",
      "24651/24651 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.92 - 2s 75us/sample - loss: 0.2029 - accuracy: 0.9234\n",
      "Epoch 30/52\n",
      "24651/24651 [==============================] - 2s 75us/sample - loss: 0.1907 - accuracy: 0.9287\n",
      "Epoch 31/52\n",
      "24651/24651 [==============================] - 2s 73us/sample - loss: 0.1974 - accuracy: 0.9260\n",
      "Epoch 32/52\n",
      "24651/24651 [==============================] - 2s 74us/sample - loss: 0.1805 - accuracy: 0.9316\n",
      "Epoch 33/52\n",
      "24651/24651 [==============================] - 3s 107us/sample - loss: 0.1823 - accuracy: 0.9307\n",
      "Epoch 34/52\n",
      "24651/24651 [==============================] - 3s 103us/sample - loss: 0.1627 - accuracy: 0.9396\n",
      "Epoch 35/52\n",
      "24651/24651 [==============================] - 4s 170us/sample - loss: 0.1638 - accuracy: 0.9388\n",
      "Epoch 36/52\n",
      "24651/24651 [==============================] - 3s 129us/sample - loss: 0.1562 - accuracy: 0.9422\n",
      "Epoch 37/52\n",
      "24651/24651 [==============================] - 2s 100us/sample - loss: 0.1585 - accuracy: 0.9402\n",
      "Epoch 38/52\n",
      "24651/24651 [==============================] - 2s 100us/sample - loss: 0.1503 - accuracy: 0.9426\n",
      "Epoch 39/52\n",
      "24651/24651 [==============================] - 2s 92us/sample - loss: 0.1464 - accuracy: 0.9463\n",
      "Epoch 40/52\n",
      "24651/24651 [==============================] - 2s 93us/sample - loss: 0.1354 - accuracy: 0.9503\n",
      "Epoch 41/52\n",
      "24651/24651 [==============================] - 2s 101us/sample - loss: 0.1352 - accuracy: 0.9497\n",
      "Epoch 42/52\n",
      "24651/24651 [==============================] - 2s 96us/sample - loss: 0.1372 - accuracy: 0.9500\n",
      "Epoch 43/52\n",
      "24651/24651 [==============================] - 2s 73us/sample - loss: 0.1259 - accuracy: 0.9543\n",
      "Epoch 44/52\n",
      "24651/24651 [==============================] - 2s 74us/sample - loss: 0.1262 - accuracy: 0.9544\n",
      "Epoch 45/52\n",
      "24651/24651 [==============================] - 2s 74us/sample - loss: 0.1321 - accuracy: 0.9516\n",
      "Epoch 46/52\n",
      "24651/24651 [==============================] - 3s 113us/sample - loss: 0.1167 - accuracy: 0.9578\n",
      "Epoch 47/52\n",
      "24651/24651 [==============================] - 3s 114us/sample - loss: 0.1189 - accuracy: 0.9569\n",
      "Epoch 48/52\n",
      "24651/24651 [==============================] - 3s 111us/sample - loss: 0.1197 - accuracy: 0.9563\n",
      "Epoch 49/52\n",
      "24651/24651 [==============================] - 3s 111us/sample - loss: 0.1125 - accuracy: 0.9593\n",
      "Epoch 50/52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24651/24651 [==============================] - 3s 111us/sample - loss: 0.1035 - accuracy: 0.9622\n",
      "Epoch 51/52\n",
      "24651/24651 [==============================] - 4s 142us/sample - loss: 0.1063 - accuracy: 0.9608\n",
      "Epoch 52/52\n",
      "24651/24651 [==============================] - 4s 144us/sample - loss: 0.1077 - accuracy: 0.9602\n",
      "2738/2738 [==============================] - 0s 119us/sample - loss: 0.0703 - accuracy: 0.9770\n"
     ]
    }
   ],
   "source": [
    "kf = KFold( n_splits=10, shuffle=True, random_state=888)\n",
    "\n",
    "neural_network = KerasClassifier(build_fn=create_network,epochs=52, batch_size=70)\n",
    "\n",
    "results=cross_val_score(neural_network, X_train, y_train, cv=kf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9648038387298584"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96093464, 0.95545822, 0.96787149, 0.96677619, 0.97626871,\n",
       "       0.96677619, 0.97152245, 0.95326763, 0.95217234, 0.97699052])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-7dab07ad3420>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# summarize history for accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'ANN.sav'\n",
    "pickle.dump(history, open(filename, 'wb'))\n",
    "#filename2 = 'ANN2.sav'\n",
    "#pickle.dump(classifier, open(filename, 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-4a5517c884b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Calling `save('my_model')` creates a SavedModel folder `my_model`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mneural_network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "# Calling `save('my_model')` creates a SavedModel folder `my_model`.\n",
    "neural_network.save('my_model')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('ANN.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
